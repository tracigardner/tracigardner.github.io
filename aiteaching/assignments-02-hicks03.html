<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="aiteaching.css" rel="stylesheet" type="text/css">
    <title>Navigating the Gray Areas: AI Ethics Case Study</title>
</head>

<body>
    <h1>Navigating the Gray Areas: AI Ethics Case Study</h1>
    <p class="byline">Assignment created by David Hicks (School of Education), using prompts with Claude AI</p>

    <div class="series-overview">
        <h2>Other Assignments In This Series</h2>
        <p>This assignment is the second week of a four-week series focused on learning about generative AI.</p>
        <ul class="series-list">
            <li><a href="https://aiteaching.vt.domains/sample-assignments/by-cohort-members/ai-in-my-world-a-personal-discovery/">AI in My World: A Personal Discovery</a></li>
            <li><a href="https://aiteaching.vt.domains/sample-assignments/by-cohort-members/co-creating-with-ai-a-dance-of-ideas/">Co-Creating with AI: A Dance of Ideas</a></li>
            <li><a href="https://aiteaching.vt.domains/sample-assignments/by-cohort-members/navigating-the-gray-areas-ai-ethics-case-study/">Navigating the Gray Areas: AI Ethics Case Study</a></li>
            <li><a href="https://aiteaching.vt.domains/sample-assignments/by-cohort-members/ai-as-a-professional-tool-discipline-specific-workshop/">AI as a Professional Tool: Discipline-Specific Workshop</a></li>
        </ul>
    </div>


    <h2>Rationale</h2>
    <p>This assignment deepens students&rsquo; understanding of AI ethics by having them analyze a real-world case study. Working in interdisciplinary groups encourages diverse perspectives and collaborative problem-solving.</p>

    <h2>Objectives</h2>
    <ul class="skipline">
        <li>Apply ethical frameworks to AI use cases.</li>
        <li>Collaborate across disciplines to solve complex problems.</li>
        <li>Develop guidelines for responsible AI use.</li>
    </ul>

    <h2>Activities</h2>

    <ol class="skipline">
        <li>Read these resources to introduce key concepts and background knowledge on AI:
            <ol class="biblio skipline">
                <li>Bostrom, Nick, and Eliezer Yudkowsky. 2011. &ldquo;<a href="https://radiobostrom.com/9/the-ethics-of-artificial-intelligence">The Ethics of Artificial Intelligence</a>.&rdquo; Radio Bostrom. https://radiobostrom.com/9/the-ethics-of-artificial-intelligence.
                </li>
                <li>Christian, Brian. 2024. &ldquo;<a href="https://www.ox.ac.uk/news/features/can-we-truly-align-ai-human-values-qa-brian-christian">Can We Truly Align AI with Human Values? - Q&A with Brian Christian</a>.&rdquo; University of Oxford News, March 27. https://www.ox.ac.uk/news/features/can-we-truly-align-ai-human-values-qa-brian-christian.
                </li>
                <li>NPR/TED Staff. 2018. &ldquo;<a href="https://www.npr.org/2018/01/26/580617998/cathy-oneil-do-algorithms-perpetuate-human-bias">Cathy O&rsquo;Neil: Do Algorithms Perpetuate Human Bias?</a>&rdquo; TED Radio Hour. NPR, January 26. https://www.npr.org/2018/01/26/580617998/cathy-oneil-do-algorithms-perpetuate-human-bias.</li>
                <li>Shahriari, Kyarash, and Mana Shahriari. 2017. &ldquo;<a href="https://doi.org/10.1109/IHTC.2017.8058187">IEEE Standard Review — Ethically Aligned Design: A Vision for Prioritizing Human Wellbeing with Artificial Intelligence and Autonomous Systems</a>.&rdquo; 2017 IEEE Canada International Humanitarian Technology Conference (IHTC), July, 197&ndash;201. https://doi.org/10.1109/IHTC.2017.8058187.</li>
                <li>Yale University, dir. 2022. <a href="https://www.youtube.com/watch?v=z6atNBhItBs">The Alignment Problem: Machine Learning and Human Values with Brian Christian</a>. 01:13:48. https://www.youtube.com/watch?v=z6atNBhItBs.
                </li>
            </ol>
        </li>

        <li>Use these questions in small group discussions or online forums to explore the readings:
            <ul>
                <li>What does it mean to align artificial intelligence with human values, and why is this alignment difficult to achieve?</li>
                <li>In what ways can AI systems unintentionally reinforce or amplify existing human biases?</li>
                <li>Who should be responsible for ensuring that AI technologies are developed and used ethically—designers, corporations, governments, or someone else?</li>
                <li>What ethical frameworks or principles do you think should guide the development of AI systems?</li>
                <li>How might differing cultural, political, or economic contexts affect perceptions of ethical AI development?</li>
                <li>What are the risks of allowing AI systems to operate autonomously in high-stakes areas like healthcare, law enforcement, or warfare?</li>
            </ul>
        </li>

        <li>Introduce the major project for this lesson:
            <blockquote>
                Dive deep into the ethical labyrinth of AI. In interdisciplinary teams, you&rsquo;ll dissect a real-world AI ethics case. Using AI to aid your research, you&rsquo;ll critically evaluate its assistance. Each team member brings their disciplinary lens, collectively crafting guidelines for responsible AI use.
            </blockquote>
        </li>



        <li>Have students follow this schedule as they work:
            <ol type="a">

                <li><strong>Team Formation (Days 1&ndash;2)</strong>
                    <ul>
                        <li>In class, network during a &ldquo;discipline speed-dating&rdquo; session.</li>
                        <li>Form 4-5 person interdisciplinary teams, each with a mix of majors.</li>
                        <li>Exchange contact info, and set up a team chat.</li>
                        <li>Establish team expectations in a team contract, <a href="https://uwaterloo.ca/centre-for-teaching-excellence/catalogs/tip-sheets/making-group-contracts">using these resources</a> from the University of Waterloo.</li>
                    </ul>
                </li>
                <li><strong>Case Study Deep Dive (Days 3&ndash;5)</strong>
                    <ul>
                        <li>Receive an AI ethics case study (See the <a href="#cases">case list</a> below).</li>
                        <li>Individually, use AI to research your case:
                            <ul class="null">
                                <li>Ask for a factual summary.</li>
                                <li>Request arguments for and against.</li>
                                <li>Seek out stakeholder perspectives.</li>
                            </ul>
                        </li>
                        <li>Keep a &ldquo;Fact vs. Framing&rdquo; journal, noting where AI seems biased.</li>
                    </ul>
                </li>
                <li><strong>Interdisciplinary Analysis (Days 6&ndash;8)</strong>
                    <ul>
                        <li>Meet as a team, each sharing their AI-assisted research.</li>
                        <li>Take turns leading a discussion from your discipline&rsquo;s view.
                            <blockquote>
                                <p style="margin-bottom: 0px;margin-top: 0px;">Example:</p>
                                <ul class="null">
                                    <li>Law Student: Copyright and authorship issues.</li>
                                    <li>Fine Arts Student: Creative intent and artistic value.</li>
                                    <li>Computer Science Student: AI model training ethics.</li>
                                    <li>Philosophy Student: What defines art and creativity?</li>
                                </ul>
                            </blockquote>
                        </li>
                        <li>Create a mind map connecting all viewpoints.</li>
                    </ul>
                </li>
                <li><strong>AI Evaluation Roundtable (Day 9)</strong>
                    <ul>
                        <li>Hold a structured roundtable on AI&rsquo;s research role:
                            <ul class="null">
                                <li>Round 1: How did AI help each member?</li>
                                <li>Round 2: Where did AI show bias or gaps?</li>
                                <li>Round 3: Lessons for responsible AI research use?</li>
                            </ul>
                        </li>
                        <li>Summarize key points in a shared doc.</li>
                    </ul>
                </li>
                <li><strong>Guidelines Workshop (Days 10&ndash;12)</strong>
                    <ul>
                        <li>Armed with insights, hold a guidelines workshop.</li>
                        <li>Silent brainstorming: Each write potential guidelines.</li>
                        <li>Group similar ideas, discuss each.</li>
                        <li>Refine into 5-7 actionable, discipline-informed guidelines.</li>
                        <li>Design a visual poster of your guidelines.</li>
                    </ul>
                </li>
                <li><strong>Presentation Prep & Delivery (Days 13&ndash;14)</strong>
                    <ul>
                        <li>Structure your 10-minute talk:
                            <ul class="null">
                                <li>Case Synopsis (2 min, Law)</li>
                                <li>Key Dilemmas (4 min, all contribute)</li>
                                <li>AI&rsquo;s Research Role (2 min, Comp Sci)</li>
                                <li>Guidelines & Call to Action (2 min, Philosophy)</li>
                            </ul>
                        </li>
                        <li>Practice with peers from another team, refine.</li>
                        <li>Present to class, displaying your poster.</li>
                    </ul>
                </li>
            </ol>
        </li>

    </ol>

    <h2 id="cases">Possible AI Ethics Cases &amp; Resources</h2>
    <ol>
        <li><strong>Correctional Offender Management Profiling for Alternative Sanctions (COMPAS) Algorithm Bias</strong>
            <ul style="margin-bottom: 24px;">
                <li>Angwin, Julia, Jeff Larson, Surya Mattu, and Lauren Kirchner. 2016. &ldquo;<a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">Machine Bias: There&rsquo;s software used across the country to predict future criminals. And it&rsquo;s biased against blacks</a>.&rdquo;
                    </a> ProPublica, May 23, 2016.</li>
                <li>Dieterich, William, Christina Mendoza, and Tim Brennan. 2016.
                    <a href="https://go.volarisgroup.com/rs/430-MBX-989/images/ProPublica_Commentary_Final_070616.pdf"> &ldquo;COMPAS Risk Scales: Demonstrating Accuracy Equity and Predictive Parity.&rdquo;
                    </a> Northpointe Inc., July 6, 2016.
                </li>
                <li>Supreme Court of Wisconsin. 2016. <a href="https://www.wicourts.gov/sc/opinion/DisplayDocument.pdf?content=pdf&seqNo=171690">
                        &ldquo;State v. Loomis, 2016 WI 68, 881 N.W.2d 749.&rdquo;</a> July 13, 2016.</li>
            </ul>
        </li>
        <li><strong>MIT&rsquo;s &ldquo;Norman&rdquo; AI Experiment</strong>
            <ul>
                <li>Fairfield, Joshua A. T. 2019. <a href="https://intr2dok.vifa-recht.de/receive/mir_mods_00007438">&ldquo;Data Diets and Democracy: The Chinese Social Credit System From a Machine Learning Perspective.&rdquo;</a> Verfassungsblog, June 25, 2019.</li>
                <li>MIT Media Lab. 2018. &ldquo;<a href="https://www.media.mit.edu/projects/norman/overview/">Norman: The World&rsquo;s First Psychopathic AI</a>.&rdquo;</li>
                <li>Wakefield, Jane. 2018. &ldquo;<a href="https://www.bbc.com/news/technology-44040008">Are you scared yet? Meet Norman, the psychopathic AI </a>.&rdquo;
                    BBC News, May 30, 2018.</li>

            </ul>
        </li>
        <li><strong>Google&rsquo;s LaMDA: Sentient or Not?</strong>
            <ul>
                <li>Collins, Eli, and Zoubin Ghahramani. 2021. &ldquo;<a href="https://blog.google/technology/ai/lamda/">LaMDA: Our Breakthrough Conversation Technology</a>.&rdquo; Google, May 18. https://blog.google/technology/ai/lamda/.</li>
                <li>Leavy, Elliot. 2025. &ldquo;<a href="https://www.aidataanalytics.network/data-science-ai/news-trends/full-transcript-google-engineer-talks-to-sentient-artificial-intelligence-2">Full Transcript: Google Engineer Talks to &lsquo;Sentient&rsquo; Artificial Intelligence</a>.&rdquo; AI, Data & Analytics Network, March 20. https://www.aidataanalytics.network/data-science-ai/news-trends/full-transcript-google-engineer-talks-to-sentient-artificial-intelligence-2.</li>
                <li>Lemoine, Blake. 2022. &ldquo;<a href="https://cajundiscordian.medium.com/what-is-lamda-and-what-does-it-want-688632134489">What Is LaMDA and What Does It Want?</a>&rdquo; Medium, June 11. https://cajundiscordian.medium.com/what-is-lamda-and-what-does-it-want-688632134489.</li>
                <li>Tallis, Raymond. 2022. &ldquo;<a href="https://web.archive.org/web/20250719085721/https://philosophynow.org/issues/152/The_Fantasy_of_Conscious_Machines">The Fantasy of Conscious Machines</a>.&rdquo; Philosophy Now, no. 152 (November). https://philosophynow.org/issues/152/The_Fantasy_of_Conscious_Machines.</li>
            </ul>
        </li>
        <li><strong>AI-Generated Art Controversy</strong>
            <ul>
                <li>Christie&rsquo;s. 2018. &ldquo;<a href="https://www.christies.com/en/stories/a-collaboration-between-two-artists-one-human-one-a-machine-0cd01f4e232f4279a525a446d60d4cd1">Can a Portrait, Created by AI, Be Called Art?</a>&rdquo; Christie&rsquo;s, December 12. https://www.christies.com/en/stories/a-collaboration-between-two-artists-one-human-one-a-machine-0cd01f4e232f4279a525a446d60d4cd1.
                </li>
                <li>Kuta, Sarah. 2022. &ldquo;<a href="https://web.archive.org/web/20221012225525/https://www.smithsonianmag.com/smart-news/how-would-van-gogh-have-painted-the-remote-faroe-islands-180980910/">How Would van Gogh Have Painted the Faroe Islands?</a>&rdquo; Smithsonian Magazine, October 12. https://www.smithsonianmag.com/smart-news/how-would-van-gogh-have-painted-the-remote-faroe-islands-180980910/?itm_source=related-content&itm_medium=parsely-api.</li>
                <li>Santos, Sabrina. 2017. &ldquo;<a href="https://www.archdaily.com/867048/ibm-watson-how-artificial-intelligence-helped-to-create-a-gaudi-inspired-thinking-sculpture">How Artificial Intelligence Helped to Create a Gaudí-Inspired Thinking Sculpture</a>.&rdquo; <em>ArchDaily</em>, March 23. https://www.archdaily.com/867048/ibm-watson-how-artificial-intelligence-helped-to-create-a-gaudi-inspired-thinking-sculpture.</li>
                <li>Wenzel, John. 2023. &ldquo;<a href="https://www.denverpost.com/2023/09/01/ai-art-colorado-state-fair-2023-rule-changes-global-controversy/">Global Controversy after AI Art-Win Prompts Rule Changes at Colorado State Fair</a>.&rdquo; 2023. <em>The Denver Post</em>, September 1. https://www.denverpost.com/2023/09/01/ai-art-colorado-state-fair-2023-rule-changes-global-controversy/.</li>
                <li>Woods, Darian, Adrian Ma, Noah Glick, Corey Bridges, and Kate Concannon, contribs. 2023. &ldquo;<a href="https://www.npr.org/2023/01/30/1152653269/artists-vs-ai">Artists vs. AI.</a>&rdquo; The Indicator on Planet Money. January 30. https://www.npr.org/2023/01/30/1152653269/artists-vs-ai.</li>
            </ul>
        </li>
        <li><strong>Predictive Policing in Los Angeles</strong>
            <ul>
                <li>National Institute of Justice. 2022. &ldquo;<a href="https://crimesolutions.ojp.gov/ratedprograms/predictive-policing-model-los-angeles-calif">Program Profile: Predictive Policing Model in Los Angeles, Calif.</a>&rsquo; November 28. https://crimesolutions.ojp.gov/ratedprograms/predictive-policing-model-los-angeles-calif.</li>
                <li>Scannell, R. Joshua. 2016. &ldquo;<a href="https://reallifemag.com/broken-windows-broken-code/">Broken Windows, Broken Code</a>.&rdquo; <em>Real Life</em>, August 29. https://reallifemag.com/broken-windows-broken-code/.</li>
                <li>Shapiro, Aaron. 2017. &ldquo;<a href="https://doi.org/10.1038/541458a">Reform Predictive Policing</a>.&rdquo; <em>Nature</em> 541 (7638): 458&ndash;60. https://doi.org/10.1038/541458a.</li>
                <li>Vargas, Aitana. 2023. &ldquo;<a href="https://centerforhealthjournalism.org/our-work/insights/reporting-long-shadow-lapds-data-driven-policing-programs">Reporting on the Long Shadow of the LAPD&rsquo;s Data-Driven Policing Programs</a>.&rdquo; USC Annenberg Center for Health Journalism, August 29. https://centerforhealthjournalism.org/our-work/insights/reporting-long-shadow-lapds-data-driven-policing-programs.</li>
            </ul>
        </li>
    </ol>








    <h2>Model Student Responses</h2>

    <h3>AI-Made Art Team</h3>
    <blockquote>
        <h4>Project: Midjourney AI Artwork Wins Colorado State Fair Prize</h4>

        <h4>Individual AI-Assisted Research</h4>
        <ul>
            <li><strong>Law Student:</strong> ChatGPT articulated copyright issues well but oversimplified &ldquo;work-for-hire&rdquo; doctrine.</li>
            <li><strong>Fine Arts Student:</strong> AI passionately argued both sides of &ldquo;creative intent,&rdquo; showing a bias toward process over product.</li>
            <li><strong>Comp Science Student:</strong> Got excellent info on Stable Diffusion&rsquo;s training but missed recent model-poisoning issues.</li>
            <li><strong>Philosophy Student:</strong> AI philosophically defined art beautifully, yet largely ignored non-Western perspectives.</li>
        </ul>

        <h4>Team&rsquo;s Ethical Guidelines (Poster)</h4>
        <ol>
            <li>Transparent AI Disclosure: Contests must require declaring AI&rsquo;s role. (Comp Sci/Law)</li>
            <li>Credit the Tributaries: AI models should list training artists, with opt-out rights. (Law/Ethics)</li>
            <li>Human as Creative Director: Entrants demonstrate iterative prompt crafting. (Fine Arts)</li>
            <li>Redefining &ldquo;Original Work&rdquo;: Update terms for the AI age, maybe &ldquo;Best AI-Human Collaboration.&rdquo; (Law/Fine Arts)</li>
            <li>Diverse Dataset Mandate: Require AI art models to prove inclusive training data. (Comp Sci/Ethics)</li>
            <li>Community Impact Assessment: Artists discuss how AI-art might affect local art scenes. (Fine Arts/Philosophy)</li>
            <li>Philosophy Foreword in Prospectus: Contextualize each contest&rsquo;s stance on &ldquo;What is art?&rdquo; (Philosophy)</li>
        </ol>

        <h4>Abstract</h4>
        <p>In our presentation, the Law student concisely explained the case&rsquo;s virality and legal ambiguities. All members then dissected key dilemmas—like the blurred line between tool and collaborator—through their disciplinary lenses. Our Computer Science major candidly discussed how ChatGPT enriched yet biased their research. Finally, our Philosophy student unveiled our guidelines, not as rigid rules, but as an evolving ethical framework, urging the arts community to collectively define creativity in the AI era.</p>

        <h4>Individual AI-Assisted Research Entries</h4>

        <h5>Law Student</h5>
        <ul>
            <li><strong>Tool:</strong> Anthropic&rsquo;s Claude</li>
            <li><strong>Initial Query:</strong> &ldquo;Summarize intellectual property issues in AI-generated art.&rdquo;</li>
            <li><strong>Response:</strong> Clear overview of copyright, mostly accurate on work-for-hire doctrine.</li>
            <li><strong>Refined:</strong> &ldquo;Does Jason Allen&rsquo;s direction make him the &lsquo;author&rsquo; of the Midjourney artwork under U.S. law? How does Burrow-Giles v. Sarony (1884) on photography apply?&rdquo;</li>
            <li><strong>Response:</strong> Excellent linkage to seminal case, but struggles with its application to AI&rsquo;s &ldquo;non-human&rdquo; nature.</li>
            <li><strong>Probing:</strong> &ldquo;In U.S. v. Google (2023), AI training data was ruled &lsquo;transformative use.&rsquo; Could AI art be seen similarly, with artists as data curators?&rdquo;</li>
            <li><strong>Response:</strong> Fascinating pivot. Analogizes artists to data curators, AI to machine learning models. Novel legal theory, though it sidesteps the critical distinction that ML models don&rsquo;t generate new content.</li>
        </ul>

        <h5>Fine Arts Students</h5>
        <ul>
            <li><strong>Tool:</strong> ChatGPT</li>
            <li><strong>First Try:</strong> &ldquo;Argue for and against AI-made art having creative merit.&rdquo;</li>
            <li><strong>Response:</strong> Passionate arguments, but Western-centric art theory.</li>
            <li><strong>Pressed:</strong> &ldquo;How does AI art challenge Kandinsky&rsquo;s theory of artistic spirituality or Banksy&rsquo;s idea of art as subversion? Do Brazilian digital artist Guto N&oacute;brega&rsquo;s views on tech-organic symbiosis support AI art?&rdquo;</li>
            <li><strong>Response:</strong> Deep dive into art theory. Compelling argument that AI lacks Kandinsky&rsquo;s &ldquo;inner necessity&rdquo; but aligns with N&oacute;brega&rsquo;s symbiosis. Fresher perspective.</li>
            <li><strong>Final Query:</strong> &ldquo;Some say Allen&rsquo;s work isn&rsquo;t &lsquo;his.&rsquo; Yet appropriation artists like Koons or Prince often don&rsquo;t physically make their art. Comparison?&rdquo;</li>
            <li><strong>Response:</strong> Eye-opening. Questions authorship norms, noting Prince&rsquo;s minimal transformations still count as &ldquo;his art.&rdquo; Biased towards post-modern views, though&mdash;did it really understand pre-modern art paradigms?</li>
        </ul>

        <h5>Computer Science Student</h5>
        <ul>
            <li><strong>Tool:</strong> Google&rsquo;s Bard</li>
            <li><strong>Base Question:</strong> &ldquo;Explain Midjourney&rsquo;s image generation tech.&rdquo;</li>
            <li><strong>Response:</strong> Good overview of GANs and transformers, but outdated&mdash;missed Midjourney&rsquo;s switch to diffusion models.</li>
            <li><strong>Refined:</strong> &ldquo;Detail Midjourney v5&rsquo;s diffusion model, DPM-Solver++, and its Custom Style system.&rdquo;</li>
            <li><strong>Response:</strong> Much better! Accurate on modern techniques, even noting custom style vectors.</li>
            <li><strong>Critical:</strong> &ldquo;Recent paper shows some LAION-5B dataset images were scraped without consent. How can Stable Diffusion & Midjourney users ensure ethical training data?&rdquo;</li>
            <li><strong>Response:</strong> Commendable pivot. Suggests cryptographic watermarking for art attribution, and federated learning to train on-device without data sharing. However, it underplayed the dataset auditing challenges&mdash;a serious oversight.</li>
        </ul>

    </blockquote>


    <h2>Assessment Rubric</h2>
    <table class="alternateTable">
        <thead style="background-color: #f0f0f0;">
            <tr>
                <th scope="col">Criteria</th>
                <th scope="col">Excellent (90-100%)</th>
                <th scope="col">Good (80-89%)</th>
                <th scope="col">Needs Improvement (70-79%)</th>
                <th scope="col">Poor (0-69%)</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <th scope="row">Case study analysis (25%)</td>
                <td>Comprehensively unpacks complexities</td>
                <td>Clearly presents key issues</td>
                <td>Covers basics, misses nuances</td>
                <td>Superficial or inaccurate</td>
            </tr>
            <tr>
                <th scope="row">Interdisciplinary collaboration (25%)</td>
                <td>All views significantly shape discussion</td>
                <td>Most views well-integrated</td>
                <td>Some views overlooked</td>
                <td>Little cross-disciplinary input</td>
            </tr>
            <tr>
                <th scope="row">AI use critique (20%)</td>
                <td>Deeply evaluates AI&rsquo;s research role</td>
                <td>Clearly assesses AI&rsquo;s impact</td>
                <td>Basic AI evaluation</td>
                <td>Little AI use reflection</td>
            </tr>
            <tr>
                <th scope="row">Guidelines quality (20%)</td>
                <td>Insightful, actionable, field-specific</td>
                <td>Clear, mostly actionable</td>
                <td>Generic or vague</td>
                <td>Inadequate or missing</td>
            </tr>
            <tr>
                <th scope="row">Presentation (10%)</td>
                <td>Engaging, clear, superb time mgmt</td>
                <td>Clear, good time mgmt</td>
                <td>Somewhat clear, timing issues</td>
                <td>Unclear or poorly timed</td>
            </tr>
        </tbody>
    </table>

    <p>&nbsp;</p>
</body>

</html>